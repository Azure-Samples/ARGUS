# ğŸ‘ï¸ ARGUS: The All-Seeing Document Intelligence Platform

<div align="center">

[![Azure](https://img.shields.io/badge/Azure-0078D4?style=for-the-badge&logo=microsoft-azure&logoColor=white)](https://azure.microsoft.com)
[![OpenAI](https://img.shields.io/badge/GPT--4-412991?style=for-the-badge&logo=openai&logoColor=white)](https://openai.com)
[![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](https://opensource.org/licenses/MIT)

*Named after Argus Panoptes, the mythological giant with a hundred eyesâ€”ARGUS never misses a detail in your documents.*

</div>

## ğŸš€ Transform Document Processing with AI Intelligence

**ARGUS** revolutionizes how organizations extract, understand, and act on document data. By combining the precision of **Azure Document Intelligence** with the contextual reasoning of **GPT-4 Vision**, ARGUS doesn't just read documentsâ€”it *understands* them.

### ğŸ’¡ Why ARGUS?

Traditional OCR solutions extract text but miss the context. AI-only approaches struggle with complex layouts. **ARGUS bridges this gap**, delivering enterprise-grade document intelligence that:

- **ğŸ¯ Extracts with Purpose**: Understands document context, not just text
- **âš¡ Scales Effortlessly**: Process thousands of documents with cloud-native architecture
- **ğŸ”’ Secures by Design**: Enterprise security with managed identities and RBAC
- **ğŸ§  Learns Continuously**: Configurable datasets adapt to your specific document types
- **ğŸ“Š Measures Success**: Built-in evaluation tools ensure consistent accuracy

---

## ğŸŒŸ Key Capabilities

<table>
<tr>
<td width="50%">

### ğŸ” **Intelligent Document Understanding**
- **Hybrid AI Pipeline**: Combines OCR precision with LLM reasoning
- **Context-Aware Extraction**: Understands relationships between data points
- **Multi-Format Support**: PDFs, images, forms, invoices, medical records
- **Zero-Shot Learning**: Works on new document types without training

### âš¡ **Enterprise-Ready Performance**
- **Cloud-Native Architecture**: Built on Azure Container Apps
- **Scalable Processing**: Handle document floods with confidence
- **Real-Time Processing**: API-driven workflows for immediate results
- **Event-Driven Automation**: Automatic processing on document upload

</td>
<td width="50%">

### ğŸ›ï¸ **Advanced Control & Customization**
- **Dynamic Configuration**: Runtime settings without redeployment
- **Custom Datasets**: Tailor extraction for your specific needs
- **Interactive Chat**: Ask questions about processed documents
- **Concurrency Management**: Fine-tune performance for your workload

### ğŸ“ˆ **Comprehensive Analytics**
- **Built-in Evaluation**: Multiple accuracy metrics and comparisons
- **Performance Monitoring**: Application Insights integration
- **Custom Evaluators**: Fuzzy matching, semantic similarity, and more
- **Visual Analytics**: Jupyter notebooks for deep analysis

</td>
</tr>
</table>

---

## ğŸ—ï¸ Architecture: Built for Scale and Security

ARGUS employs a modern, cloud-native architecture designed for enterprise workloads:

<div align="center">

```mermaid
graph TB
    subgraph "ğŸ“¥ Document Input"
        A[ğŸ“„ Documents] --> B[ğŸ“ Azure Blob Storage]
        C[ğŸŒ Direct Upload API] --> D[ğŸš€ FastAPI Backend]
    end
    
    subgraph "ğŸ§  AI Processing Engine"
        B --> D
        D --> E[ğŸ” Azure Document Intelligence]
        D --> F[ï¿½ GPT-4 Vision]
        E --> G[âš™ï¸ Hybrid Processing Pipeline]
        F --> G
    end
    
    subgraph "ğŸ’¡ Intelligence & Analytics"
        G --> H[ğŸ“Š Custom Evaluators]
        G --> I[ğŸ’¬ Interactive Chat]
        H --> J[ğŸ“ˆ Results & Analytics]
    end
    
    subgraph "ğŸ’¾ Data Layer"
        G --> K[ğŸ—„ï¸ Azure Cosmos DB]
        J --> K
        I --> K
        K --> L[ğŸ“± Streamlit Frontend]
    end
    
    subgraph "ğŸ” Security & Infrastructure"
        M[ğŸ”’ Managed Identity] -.-> D
        N[ğŸ“Š Application Insights] -.-> D
        O[ğŸ›¡ï¸ RBAC] -.-> B
        O -.-> K
        P[ğŸ—ï¸ Container Registry] -.-> D
    end
    
    style A fill:#e1f5fe
    style D fill:#f3e5f5
    style G fill:#fff3e0
    style K fill:#e8f5e8
```

</div>

### ğŸ”§ Infrastructure Components

| Component | Technology | Purpose |
|-----------|------------|---------|
| **ğŸš€ Backend API** | Azure Container Apps + FastAPI | High-performance document processing engine |
| **ğŸ“± Frontend UI** | Streamlit (Optional) | Interactive document management interface |
| **ğŸ“ Document Storage** | Azure Blob Storage | Secure, scalable document repository |
| **ğŸ—„ï¸ Metadata Database** | Azure Cosmos DB | Results, configurations, and analytics |
| **ğŸ” OCR Engine** | Azure Document Intelligence | Structured text and layout extraction |
| **ğŸ§  AI Reasoning** | Azure OpenAI (GPT-4 Vision) | Contextual understanding and extraction |
| **ğŸ—ï¸ Container Registry** | Azure Container Registry | Private, secure container images |
| **ğŸ”’ Security** | Managed Identity + RBAC | Zero-credential architecture |
| **ğŸ“Š Monitoring** | Application Insights | Performance and health monitoring |

---

## âš¡ Quick Start: Deploy in Minutes

### ğŸ“‹ Prerequisites

<details>
<summary><b>ğŸ› ï¸ Required Tools (Click to expand)</b></summary>

1. **Docker**
   ```bash
   # Install Docker (required for containerization during deployment)
   # Visit https://docs.docker.com/get-docker/ for installation instructions
   ```

2. **Azure Developer CLI (azd)**
   ```bash
   curl -fsSL https://aka.ms/install-azd.sh | bash
   ```

3. **Azure CLI**
   ```bash
   curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash
   ```

4. **Azure OpenAI Resource** 
   - Create an Azure OpenAI resource in a [supported region](https://docs.microsoft.com/azure/cognitive-services/openai/overview#regional-availability)
   - Deploy a vision-capable model: `gpt-4o`, `gpt-4-turbo`, or `gpt-4` (with vision)
   - Collect: endpoint URL, API key, and deployment name

</details>

### ğŸš€ One-Command Deployment

```bash
# 1. Clone the repository
git clone https://github.com/Azure-Samples/ARGUS.git
cd ARGUS

# 2. Login to Azure
az login

# 3. Configure your Azure OpenAI credentials
cp .env.template .env
# Edit .env with your Azure OpenAI details

# 4. Deploy everything with a single command
azd up
```

**That's it!** ğŸ‰ Your ARGUS instance is now running in the cloud.

### âœ… Verify Your Deployment

```bash
# Check system health
curl "$(azd env get-value BACKEND_URL)/health"

# Expected response:
{
  "status": "healthy",
  "services": {
    "cosmos_db": "âœ… connected",
    "blob_storage": "âœ… connected", 
    "document_intelligence": "âœ… connected",
    "azure_openai": "âœ… connected"
  }
}

# View live application logs
azd logs --follow
```

---

## ğŸ® Usage Examples: See ARGUS in Action

### ğŸ“„ Example 1: Process an Invoice

```bash
# Upload an invoice to process
az storage blob upload \
  --account-name "$(azd env get-value STORAGE_ACCOUNT_NAME)" \
  --container-name "datasets" \
  --name "default-dataset/invoice-2024.pdf" \
  --file "./my-invoice.pdf" \
  --auth-mode login

# Process it with ARGUS
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "blob_url": "https://mystorage.blob.core.windows.net/datasets/default-dataset/invoice-2024.pdf"
  }' \
  "$(azd env get-value BACKEND_URL)/api/process-blob"

# Response includes extracted data:
{
  "status": "success",
  "extraction_results": {
    "invoice_number": "INV-2024-001",
    "total_amount": "$1,250.00",
    "vendor_name": "Acme Corp",
    "line_items": [...]
  },
  "confidence_score": 0.94,
  "processing_time": "2.3s"
}
```

### ğŸ’¬ Example 2: Interactive Document Chat

```bash
# Ask questions about any processed document
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "blob_url": "https://mystorage.blob.core.windows.net/datasets/default-dataset/contract.pdf",
    "question": "What are the key terms and conditions in this contract?"
  }' \
  "$(azd env get-value BACKEND_URL)/api/chat"

# Get intelligent answers:
{
  "answer": "The key terms include: 1) 12-month service agreement, 2) $5000/month fee, 3) 30-day termination clause...",
  "confidence": 0.91,
  "sources": ["page 1, paragraph 3", "page 2, section 2.1"]
}
```

### ğŸ“¤ Example 3: Direct File Upload

```bash
# Process a file without pre-uploading to storage
curl -X POST \
  -F "file=@./medical-form.pdf" \
  -F "dataset_name=medical-dataset" \
  "$(azd env get-value BACKEND_URL)/api/process-file"
```

---

## ğŸ›ï¸ Advanced Configuration

### ğŸ“Š Dataset Management

ARGUS supports unlimited custom document types through configurable datasets:

<details>
<summary><b>ğŸ—‚ï¸ Built-in Datasets</b></summary>

- **`default-dataset/`**: Invoices, receipts, general business documents
- **`medical-dataset/`**: Medical forms, prescriptions, healthcare documents

</details>

<details>
<summary><b>ğŸ”§ Create Custom Datasets</b></summary>

You can create custom datasets either manually in Cosmos DB or through the Streamlit frontend interface:

**Option 1: Using the Frontend (Recommended)**
1. Access the Streamlit frontend (deployed automatically with azd)
2. Navigate to the Settings tab
3. Create a new dataset with custom prompts and schema

**Option 2: Manual Setup**
1. **Create dataset structure**:
   ```bash
   mkdir demo/financial-reports
   ```

2. **Define extraction instructions** (`system_prompt.txt`):
   ```text
   Extract financial data from quarterly reports with focus on:
   - Revenue figures and growth percentages
   - Key performance indicators
   - Risk factors and forward-looking statements
   - Executive summary highlights
   ```

3. **Specify output format** (`output_schema.json`):
   ```json
   {
     "company_name": "",
     "quarter": "",
     "revenue": "",
     "growth_rate": "",
     "key_metrics": {
       "profit_margin": "",
       "cash_flow": "",
       "debt_ratio": ""
     },
     "forward_outlook": ""
   }
   ```

4. **Upload documents**:
   ```bash
   az storage blob upload \
     --container-name "datasets" \
     --name "financial-reports/q3-2024.pdf" \
     --file "./report.pdf"
   ```

</details>

---

## ğŸ–¥ï¸ Frontend Interface: User-Friendly Document Management

The Streamlit frontend is **automatically deployed** with `azd up` and provides a user-friendly interface for document management.

<div align="center">
<img src="docs/ArchitectureOverview.png" alt="ARGUS Frontend Interface" width="800"/>
</div>

### ğŸ¯ Frontend Features

| Tab | Functionality |
|-----|---------------|
| **ğŸ§  Process Files** | Drag-and-drop document upload with real-time processing status |
| **ğŸ” Explore Data** | Browse processed documents, search results, view extraction details |
| **âš™ï¸ Settings** | Configure datasets, adjust processing parameters, manage connections |
| **ğŸ“‹ Instructions** | Interactive help, API documentation, and usage examples |

---

## ï¸ Development & Customization

### ğŸ—ï¸ Backend Architecture Deep Dive

```
src/containerapp/
â”œâ”€â”€ ğŸš€ main.py              # FastAPI app & route definitions
â”œâ”€â”€ ğŸ”Œ api_routes.py        # API endpoint implementations  
â”œâ”€â”€ ğŸ”§ dependencies.py      # Azure service client management
â”œâ”€â”€ ğŸ“‹ models.py           # Data models & validation schemas
â”œâ”€â”€ âš™ï¸ blob_processing.py   # Document processing pipeline
â”œâ”€â”€ ğŸ›ï¸ logic_app_manager.py # Concurrency & workflow management
â””â”€â”€ ğŸ§  ai_ocr/             # Core AI processing engine
    â”œâ”€â”€ ğŸ” process.py      # Main processing orchestration
    â”œâ”€â”€ ğŸ”— chains.py       # LangChain integration & workflows
    â”œâ”€â”€ ğŸ¤– model.py        # Azure OpenAI client & prompting
    â””â”€â”€ â±ï¸ timeout.py      # Processing timeout & error handling
```

### ğŸ§ª Local Development Setup

```bash
# Setup development environment
cd src/containerapp
python -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows
pip install -r requirements.txt

# Configure local environment
cp ../../.env.template .env
# Edit .env with your development credentials

# Run with hot reload
uvicorn main:app --reload --host 0.0.0.0 --port 8000

# Access API documentation
open http://localhost:8000/docs
```

### ğŸ”§ Key Technologies & Libraries

| Category | Technologies |
|----------|-------------|
| **ğŸš€ API Framework** | FastAPI, Uvicorn, Pydantic |
| **ğŸ§  AI/ML** | LangChain, OpenAI SDK, Azure AI SDK |
| **â˜ï¸ Azure Services** | Azure SDK (Blob, Cosmos, Document Intelligence) |
| **ğŸ“„ Document Processing** | PyMuPDF, Pillow, PyPDF2 |
| **ğŸ“Š Data & Analytics** | Pandas, NumPy, Matplotlib |
| **ğŸ”’ Security** | Azure Identity, managed identities |

---

##  API Reference: Complete Documentation

### ğŸš€ Core Processing Endpoints

<details>
<summary><b>ğŸ“„ POST /api/process-blob - Process Document from Storage</b></summary>

**Request**:
```json
{
  "blob_url": "https://storage.blob.core.windows.net/datasets/default-dataset/invoice.pdf",
  "dataset_name": "default-dataset",
  "priority": "normal",
  "webhook_url": "https://your-app.com/webhooks/argus",
  "metadata": {
    "source": "email_attachment",
    "user_id": "user123"
  }
}
```

**Response**:
```json
{
  "status": "success",
  "job_id": "job_12345",
  "extraction_results": {
    "invoice_number": "INV-2024-001",
    "total_amount": "$1,250.00",
    "confidence_score": 0.94
  },
  "processing_time": "2.3s",
  "timestamp": "2024-01-15T10:30:00Z"
}
```

</details>

<details>
<summary><b>ğŸ“¤ POST /api/process-file - Direct File Upload</b></summary>

**Request** (multipart/form-data):
```
file: [PDF/Image file]
dataset_name: "default-dataset"
priority: "high"
```

**Response**:
```json
{
  "status": "success",
  "job_id": "job_12346",
  "blob_url": "https://storage.blob.core.windows.net/temp/uploaded_file.pdf",
  "extraction_results": {...},
  "processing_time": "1.8s"
}
```

</details>

<details>
<summary><b>ğŸ’¬ POST /api/chat - Interactive Document Q&A</b></summary>

**Request**:
```json
{
  "blob_url": "https://storage.blob.core.windows.net/datasets/contract.pdf",
  "question": "What are the payment terms and penalties for late payment?",
  "context": "focus on financial obligations",
  "temperature": 0.1
}
```

**Response**:
```json
{
  "answer": "Payment terms are Net 30 days. Late payment penalty is 1.5% per month on outstanding balance...",
  "confidence": 0.91,
  "sources": [
    {"page": 2, "section": "Payment Terms"},
    {"page": 5, "section": "Default Provisions"}
  ],
  "processing_time": "1.2s"
}
```

</details>

### âš™ï¸ Configuration Management

<details>
<summary><b>ğŸ”§ GET/POST /api/configuration - System Configuration</b></summary>

**GET Response**:
```json
{
  "openai_settings": {
    "endpoint": "https://your-openai.openai.azure.com/",
    "model": "gpt-4o",
    "temperature": 0.1,
    "max_tokens": 4000
  },
  "processing_settings": {
    "max_concurrent_jobs": 5,
    "timeout_seconds": 300,
    "retry_attempts": 3
  },
  "datasets": ["default-dataset", "medical-dataset", "financial-reports"]
}
```

**POST Request**:
```json
{
  "openai_settings": {
    "temperature": 0.05,
    "max_tokens": 6000
  },
  "processing_settings": {
    "max_concurrent_jobs": 8
  }
}
```

</details>

### ğŸ“Š Monitoring & Analytics

<details>
<summary><b>ğŸ“ˆ GET /api/metrics - Performance Metrics</b></summary>

**Response**:
```json
{
  "period": "last_24h",
  "summary": {
    "total_documents": 1247,
    "successful_extractions": 1198,
    "failed_extractions": 49,
    "success_rate": 96.1,
    "avg_processing_time": "2.3s"
  },
  "performance": {
    "p50_processing_time": "1.8s",
    "p95_processing_time": "4.2s",
    "p99_processing_time": "8.1s"
  },
  "errors": {
    "ocr_failures": 12,
    "ai_timeouts": 8,
    "storage_issues": 3,
    "other": 26
  }
}
```

</details>

---

## ğŸ§ª Testing & Quality Assurance

ARGUS includes built-in evaluation tools for accuracy assessment. Use the Jupyter notebook in the `notebooks/` directory to run comprehensive evaluations:

```bash
# Setup evaluation environment
cd notebooks
pip install -r requirements.txt
cp ../.env.template .env  # Add your credentials

# Launch evaluation dashboard
jupyter notebook evaluator.ipynb
```

The evaluation notebook provides performance metrics, field-level analysis, and comparative assessments using various evaluation methods including fuzzy string matching and semantic similarity.

---

## ğŸ¤ Contributing & Community

### ğŸ¯ How to Contribute

We welcome contributions! Here's how to get started:

1. **ğŸ´ Fork & Clone**:
   ```bash
   git clone https://github.com/your-username/ARGUS.git
   cd ARGUS
   ```

2. **ğŸŒ¿ Create Feature Branch**:
   ```bash
   git checkout -b feature/amazing-improvement
   ```

3. **ğŸ§ª Develop & Test**:
   ```bash
   # Setup development environment
   ./scripts/setup-dev.sh
   
   # Run tests
   pytest tests/ -v
   
   # Lint code
   black src/ && flake8 src/
   ```

4. **ğŸ“ Document Changes**:
   ```bash
   # Update documentation
   # Add examples to README
   # Update API documentation
   ```

5. **ğŸš€ Submit PR**:
   ```bash
   git commit -m "feat: add amazing improvement"
   git push origin feature/amazing-improvement
   # Create pull request on GitHub
   ```

### ğŸ“‹ Contribution Guidelines

| Type | Guidelines |
|------|------------|
| **ğŸ› Bug Fixes** | Include reproduction steps, expected vs actual behavior |
| **âœ¨ New Features** | Discuss in issues first, include tests and documentation |
| **ğŸ“š Documentation** | Clear examples, practical use cases, proper formatting |
| **ğŸ”§ Performance** | Benchmark results, before/after comparisons |

### ğŸ† Recognition

Contributors will be recognized in:
- ğŸ“ Release notes for significant contributions
- ğŸŒŸ Contributors section (with permission)
- ğŸ’¬ Community showcase for innovative use cases

---

## ğŸ“ Support & Resources

### ğŸ’¬ Getting Help

| Resource | Description | Link |
|----------|-------------|------|
| **ğŸ“š Documentation** | Complete setup and usage guides | [docs/](docs/) |
| **ğŸ› Issue Tracker** | Bug reports and feature requests | [GitHub Issues](https://github.com/Azure-Samples/ARGUS/issues) |
| **ğŸ’¡ Discussions** | Community Q&A and ideas | [GitHub Discussions](https://github.com/Azure-Samples/ARGUS/discussions) |
| **ğŸ“§ Team Contact** | Direct contact for enterprise needs | See team section below |

### ğŸ”— Additional Resources

- **ğŸ“– Azure Document Intelligence**: [Official Documentation](https://docs.microsoft.com/azure/applied-ai-services/form-recognizer/)
- **ğŸ¤– Azure OpenAI**: [Service Documentation](https://docs.microsoft.com/azure/cognitive-services/openai/)
- **âš¡ FastAPI**: [Framework Documentation](https://fastapi.tiangolo.com/)
- **ğŸ LangChain**: [Integration Guides](https://python.langchain.com/)

---

## ğŸ‘¥ Team

- **Alberto Gallo** - AI Architecture & Processing Pipeline
- **Petteri Johansson** - Cloud Infrastructure & DevOps  
- **Christin Pohl** - Security & Compliance
- **Konstantinos Mavrodis** - Platform Engineering & Performance

## License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

<div align="center">

## ğŸš€ Ready to Transform Your Document Processing?

**Deploy ARGUS in minutes and start extracting intelligence from your documents today!**

```bash
git clone https://github.com/Azure-Samples/ARGUS.git && cd ARGUS && azd up
```

<br>

[![Deploy to Azure](https://aka.ms/deploytoazurebutton)](https://portal.azure.com/#create/Microsoft.Template)
[![Open in Dev Container](https://img.shields.io/static/v1?label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/Azure-Samples/ARGUS)

<br>

**â­ Star this repo if ARGUS helps your document processing needs!**

</div>
