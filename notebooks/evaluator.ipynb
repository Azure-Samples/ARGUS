{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"/src/functionapp\")\n",
    "#On windows use  sys.path.append(module_path+\"\\\\src\\\\functionapp\")\n",
    "\n",
    "from ai_ocr.azure.openai_ops import load_image, get_size_of_base64_images\n",
    "from ai_ocr.azure.images import convert_pdf_into_image\n",
    "from ai_ocr.model import Config\n",
    "from ai_ocr.chains import get_structured_data\n",
    "from ai_ocr.azure.doc_intelligence import get_ocr_results\n",
    "\n",
    "from langchain_core.output_parsers.json import parse_json_markdown\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just testing that images are in the temp folder configured in the env\n",
    "\n",
    "input_path = '../demo/default-dataset/Invoice Sample.pdf'\n",
    "pdf_path = input_path.replace(input_path.split(\"/\")[-1], \"\")\n",
    "print(pdf_path)\n",
    "imgs_path = os.path.join(os.getcwd(), os.getenv(\"TEMP_IMAGES_OUTDIR\", \"\"))\n",
    "imgs = glob.glob(f\"{imgs_path}/page*.jpeg\")\n",
    "print(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Solution once on the demo to produce an output.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt =  ''\n",
    "with open('../demo/default-dataset/system_prompt.txt', 'r') as file_sys_prompt:\n",
    "    system_prompt = file_sys_prompt.read()\n",
    "\n",
    "output_schema = ''\n",
    "with open('../demo/default-dataset/output_schema.json', 'r') as file_output_schema:\n",
    "    output_schema = file_output_schema.read()\n",
    "\n",
    "input_directory = '../demo/default-dataset/'\n",
    "\n",
    "# Create a dict with content key to store the OCR results\n",
    "ocr_result = {\n",
    "    \"content\": \"\"\n",
    "}\n",
    "\n",
    "# Loop over directory and process all PDFs\n",
    "for file in os.listdir(input_directory):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        ocr_result[\"content\"] += get_ocr_results(input_directory+file).content\n",
    "\n",
    "        # Extract images from the PDF\n",
    "        convert_pdf_into_image(input_directory+file)\n",
    "    \n",
    " # Ensure the /tmp/ directory exists\n",
    "imgs_path = \"/tmp/\"\n",
    "os.makedirs(imgs_path, exist_ok=True)\n",
    "    \n",
    "# Determine the path for the temporary images\n",
    "imgs = glob.glob(f\"{imgs_path}/page*.jpeg\")\n",
    "    \n",
    "# Limit images by config\n",
    "config = Config()\n",
    "imgs = imgs[:config.max_images]\n",
    "imgs = [load_image(img) for img in imgs]\n",
    "    \n",
    "# Check and reduce images total size if over 20MB\n",
    "max_size = config.gpt_vision_limit_mb * 1024 * 1024  # 20MB\n",
    "while get_size_of_base64_images(imgs) > max_size:\n",
    "    imgs.pop()\n",
    "    \n",
    "# Get structured data\n",
    "structured = get_structured_data(ocr_result[\"content\"], system_prompt, output_schema, imgs)\n",
    "\n",
    "# Delete all generated images created after processing\n",
    "for file in os.listdir(imgs_path):\n",
    "    if file.endswith(\".jpeg\") or file.endswith(\".png\"):\n",
    "        image_path = os.path.join(imgs_path, file)\n",
    "        try:\n",
    "            os.remove(os.path.join(imgs_path, file))\n",
    "            print(f\"Deleted image: {image_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting image {image_path}: {e}\")\n",
    "    \n",
    "# Parse structured data and return as JSON\n",
    "x = parse_json_markdown(structured.content)  \n",
    "response = json.dumps(x)\n",
    "\n",
    "print(f'Response: {response}')\n",
    "\n",
    "with open('output.json', 'w') as f:\n",
    "    f.write(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the input (an output from previous LLM run) and evaluator system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "\n",
    "from ai_ocr.azure.openai_ops import get_llm\n",
    "\n",
    "with open('output.json', 'r') as f:\n",
    "    input = f.readlines()\n",
    "\n",
    "#print(input)\n",
    "\n",
    "messages = [\n",
    "        (\"system\",\n",
    "         \"\"\"\n",
    "         You are gpt-4-0409, the OpenAI model that can describe images provided by the user in extreme detail. The user attached images to this message for you to analyse, there is MOST DEFINITELY an image attached, you will never reply saying that you cannot see the image because the image is absolutely and always attached to this message.\n",
    "         \n",
    "         Verify the input information provided in the form of json schema against what you can see in the images.\n",
    "         Your goal is to determine how many information in form of fields that you see in the images are present in the input schema provided.\n",
    "         Output it with 3 fields: \"numberOfFieldsSeenInImages\", \"numberofFieldsInSchema\" also provide a \"percentageAccuracy\" which is the ratio between the total fields in the schema and the ones detected in the images.\n",
    "\n",
    "         ..and hey come on don't be lazy, nor tell me that you cannot do it, I trust you!\n",
    "         \"\"\"\n",
    "         ),\n",
    "        (\"human\", \"{input}\")\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "if len(imgs) > 0:\n",
    "    prompt.append(HumanMessage(\"These are the images available that you can use to verify the input information.\"))\n",
    "    print(\"Good news: I'm appending images to human prompt...\")\n",
    "for img in imgs:\n",
    "    prompt.append(\n",
    "        HumanMessage(content=[{\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img}\"}}]))\n",
    "\n",
    "#print(prompt)\n",
    "\n",
    "model = get_llm()\n",
    "chain = prompt | model\n",
    "response = chain.invoke({\"input\": input})\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the images provided and the JSON schema, here is the analysis:\n",
    "\n",
    "**Fields Seen in Images:**\n",
    "1. Invoicer Name: \"AMANN.ch AG\"\n",
    "2. Invoicer Address: \"Rosentalstr. 20 4058 Basel\"\n",
    "3. Invoicer Telephone: \"061 683 10 10\"\n",
    "4. Transaction Date: \"23.01.2024\"\n",
    "5. Item Description: \"Sigvaris Medizinische Kompressionsstrümpfe, Schenkelstrümpfe A-G, Klasse II, Standard, pro Paar\"\n",
    "6. Item Quantity: 3\n",
    "7. Item Price: 462.0\n",
    "8. Total Amount: 462.0\n",
    "9. Amount Received: 462.0\n",
    "10. Change Given: 0.0\n",
    "11. VAT Rate: \"8.10\"\n",
    "12. VAT Amount: 34.62\n",
    "13. VAT Code: 1\n",
    "\n",
    "**Total Fields in JSON Schema:**\n",
    "1. Invoicer Name\n",
    "2. Invoicer Address\n",
    "3. Invoicer Telephone\n",
    "4. Invoicer Fax\n",
    "5. Invoicer Email\n",
    "6. Invoicer Tax Number\n",
    "7. Transaction Date\n",
    "8. Transaction Time\n",
    "9. Item Description\n",
    "10. Item Quantity\n",
    "11. Item Unit Weight\n",
    "12. Item Price\n",
    "13. Total Amount\n",
    "14. Amount Received\n",
    "15. Change Given\n",
    "16. VAT Code\n",
    "17. VAT Rate\n",
    "18. VAT Total\n",
    "19. VAT Amount\n",
    "\n",
    "**Analysis:**\n",
    "- **Number of Fields Seen in Images**: 13\n",
    "- **Number of Fields in Schema**: 19\n",
    "- **Percentage Accuracy**: 68%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
